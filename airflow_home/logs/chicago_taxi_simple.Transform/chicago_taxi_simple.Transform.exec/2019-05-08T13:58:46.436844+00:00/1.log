[2019-05-08 16:04:49,587] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: chicago_taxi_simple.Transform.chicago_taxi_simple.Transform.exec 2019-05-08T13:58:46.436844+00:00 [queued]>
[2019-05-08 16:04:49,706] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: chicago_taxi_simple.Transform.chicago_taxi_simple.Transform.exec 2019-05-08T13:58:46.436844+00:00 [queued]>
[2019-05-08 16:04:49,707] {__init__.py:1353} INFO - 
--------------------------------------------------------------------------------
[2019-05-08 16:04:49,707] {__init__.py:1354} INFO - Starting attempt 1 of 1
[2019-05-08 16:04:49,707] {__init__.py:1355} INFO - 
--------------------------------------------------------------------------------
[2019-05-08 16:04:49,720] {__init__.py:1374} INFO - Executing <Task(PythonOperator): chicago_taxi_simple.Transform.exec> on 2019-05-08T13:58:46.436844+00:00
[2019-05-08 16:04:49,720] {base_task_runner.py:119} INFO - Running: [u'airflow', u'run', 'chicago_taxi_simple.Transform', 'chicago_taxi_simple.Transform.exec', '2019-05-08T13:58:46.436844+00:00', u'--job_id', '22', u'--raw', u'-sd', u'DAGS_FOLDER/taxi/taxi_pipeline_simple.py', u'--cfg_path', '/var/folders/jw/6_2vfq291nsd3m1zjpt4t3k07hs8bd/T/tmp509r_6']
[2019-05-08 16:04:50,166] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec /Users/benjamin.wang/devel/github/tutorial_tfx/env/lib/python2.7/site-packages/airflow/configuration.py:590: DeprecationWarning: You have two airflow.cfg files: /Users/benjamin.wang/airflow/airflow.cfg and /Users/benjamin.wang/devel/github/tutorial_tfx/airflow_home/airflow.cfg. Airflow used to look at ~/airflow/airflow.cfg, even when AIRFLOW_HOME was set to a different value. Airflow will now only read /Users/benjamin.wang/devel/github/tutorial_tfx/airflow_home/airflow.cfg, and you should remove the other file
[2019-05-08 16:04:50,166] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec   category=DeprecationWarning,
[2019-05-08 16:04:50,694] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec [2019-05-08 16:04:50,693] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-05-08 16:04:50,886] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec [2019-05-08 16:04:50,885] {__init__.py:305} INFO - Filling up the DagBag from /Users/benjamin.wang/devel/github/tutorial_tfx/airflow_home/dags/taxi/taxi_pipeline_simple.py
[2019-05-08 16:04:54,091] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec [2019-05-08 16:04:54,091] {cli.py:517} INFO - Running <TaskInstance: chicago_taxi_simple.Transform.chicago_taxi_simple.Transform.exec 2019-05-08T13:58:46.436844+00:00 [running]> on host nlhfd-lt1436.corp.irdeto.com
[2019-05-08 16:04:54,101] {python_operator.py:104} INFO - Exporting the following env vars:
AIRFLOW_CTX_TASK_ID=chicago_taxi_simple.Transform.exec
AIRFLOW_CTX_DAG_ID=chicago_taxi_simple.Transform
AIRFLOW_CTX_EXECUTION_DATE=2019-05-08T13:58:46.436844+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill_2019-05-08T13:58:46.436844+00:00
[2019-05-08 16:04:54,113] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,112] {tf_logging.py:115} INFO - Starting Executor execution.
[2019-05-08 16:04:54,113] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,113] {tf_logging.py:115} INFO - Inputs for Executor is: {u'input_data': [ExamplesPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/train/.2, ExamplesPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/eval/.3], u'schema': [SchemaPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/SchemaGen/output/3/.6]}
[2019-05-08 16:04:54,113] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,113] {tf_logging.py:115} INFO - Execution properties for Executor is: {u'log_root': u'/var/tmp/tfx/logs/chicago_taxi_simple/Transform', u'module_file': u'/Users/benjamin.wang/devel/github/tutorial_tfx/taxi_utils.py'}
[2019-05-08 16:04:54,113] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,113] {tf_logging.py:115} INFO - Outputs for Executor is: {u'transform_output': [TransformPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.0], u'transformed_examples': [ExamplesPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/train/.0, ExamplesPath:/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/eval/.0]}
[2019-05-08 16:04:54,127] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,127] {tf_logging.py:115} INFO - Inputs to executor.Transform function: {'preprocessing_fn': u'/Users/benjamin.wang/devel/github/tutorial_tfx/taxi_utils.py', 'transform_only_data_paths': '/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/eval/*', 'analyze_and_transform_data_paths': '/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/train/*', 'tft_statistics_use_tfdv': True, 'schema_path': u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/SchemaGen/output/3/schema.pbtxt', 'compute_statistics': False, 'examples_data_format': 'FORMAT_TF_EXAMPLE'}
[2019-05-08 16:04:54,127] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,127] {tf_logging.py:115} INFO - Outputs to executor.Transform function: {'transform_materialize_output_paths': [u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/train/transformed_examples', u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/eval/transformed_examples'], 'temp_path': '/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path', 'transform_output_path': u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/'}
[2019-05-08 16:04:54,130] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,130] {tf_logging.py:115} INFO - Analyze and transform data patterns: [(0, '/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/train/*')]
[2019-05-08 16:04:54,130] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,130] {tf_logging.py:115} INFO - Transform data patterns: [(0, '/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/CsvExampleGen/examples/1/eval/*')]
[2019-05-08 16:04:54,130] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,130] {tf_logging.py:115} INFO - Transform materialization output paths: [(0, u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/train/transformed_examples'), (1, u'/Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transformed_examples/4/eval/transformed_examples')]
[2019-05-08 16:04:54,131] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,130] {tf_logging.py:115} INFO - Transform output path: /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/
[2019-05-08 16:04:54,132] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,132] {pipeline.py:143} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.
[2019-05-08 16:04:54,477] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,477] {tf_logging.py:125} WARNING - From /Users/benjamin.wang/devel/github/tutorial_tfx/env/lib/python2.7/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
[2019-05-08 16:04:54,630] {base_task_runner.py:101} INFO - Job 22: Subtask chicago_taxi_simple.Transform.exec 2019-05-08 16:04:54.629907: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2019-05-08 16:04:54,642] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,642] {tf_logging.py:115} INFO - Assets added to graph.
[2019-05-08 16:04:54,642] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,642] {tf_logging.py:115} INFO - No assets to write.
[2019-05-08 16:04:54,677] {logging_mixin.py:95} INFO - [2019-05-08 16:04:54,677] {tf_logging.py:115} INFO - SavedModel written to: /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path/tftransform_tmp/73c5f20f5d05458fbd845b92f63afbfb/saved_model.pb
[2019-05-08 16:04:56,117] {logging_mixin.py:95} INFO - [2019-05-08 16:04:56,117] {tf_logging.py:115} INFO - Assets added to graph.
[2019-05-08 16:04:56,117] {logging_mixin.py:95} INFO - [2019-05-08 16:04:56,117] {tf_logging.py:115} INFO - No assets to write.
[2019-05-08 16:04:56,152] {logging_mixin.py:95} INFO - [2019-05-08 16:04:56,152] {tf_logging.py:115} INFO - SavedModel written to: /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path/tftransform_tmp/b245b463d66c4945a0cf489bc7b106c5/saved_model.pb
[2019-05-08 16:04:59,450] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,450] {fn_api_runner_transforms.py:468} INFO - ==================== <function annotate_downstream_side_inputs at 0x12dfbb758> ====================
[2019-05-08 16:04:59,456] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,455] {fn_api_runner_transforms.py:468} INFO - ==================== <function fix_side_input_pcoll_coders at 0x12dfbb848> ====================
[2019-05-08 16:04:59,460] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,460] {fn_api_runner_transforms.py:468} INFO - ==================== <function lift_combiners at 0x12dfbb8c0> ====================
[2019-05-08 16:04:59,469] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,469] {fn_api_runner_transforms.py:468} INFO - ==================== <function expand_sdf at 0x12dfbb938> ====================
[2019-05-08 16:04:59,472] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,472] {fn_api_runner_transforms.py:468} INFO - ==================== <function expand_gbk at 0x12dfbb9b0> ====================
[2019-05-08 16:04:59,477] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,477] {fn_api_runner_transforms.py:468} INFO - ==================== <function sink_flattens at 0x12dfbbaa0> ====================
[2019-05-08 16:04:59,481] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,481] {fn_api_runner_transforms.py:468} INFO - ==================== <function greedily_fuse at 0x12dfbbb18> ====================
[2019-05-08 16:04:59,497] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,497] {fn_api_runner_transforms.py:468} INFO - ==================== <function read_to_impulse at 0x12dfbbb90> ====================
[2019-05-08 16:04:59,500] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,500] {fn_api_runner_transforms.py:468} INFO - ==================== <function impulse_to_input at 0x12dfbbc08> ====================
[2019-05-08 16:04:59,502] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,502] {fn_api_runner_transforms.py:468} INFO - ==================== <function inject_timer_pcollections at 0x12dfbbd70> ====================
[2019-05-08 16:04:59,504] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,504] {fn_api_runner_transforms.py:468} INFO - ==================== <function sort_stages at 0x12dfbbde8> ====================
[2019-05-08 16:04:59,506] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,505] {fn_api_runner_transforms.py:468} INFO - ==================== <function window_pcollection_coders at 0x12dfbbe60> ====================
[2019-05-08 16:04:59,544] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,543] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/CreateSavedModelForAnalyzerInputs[0]/CreateSavedModel/Read_13)+(ref_PCollection_PCollection_6/Write)
[2019-05-08 16:04:59,566] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,566] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_ReadAnalysisDataset[0]/Read/Read_4)+((ref_AppliedPTransform_ReadAnalysisDataset[0]/AddKey_5)+((ref_AppliedPTransform_ReadAnalysisDataset[0]/ParseExamples_6)+((ref_AppliedPTransform_DecodeAnalysisDataset[0]/ApplyDecodeFn_8)+(FlattenAnalysisDatasets/Write/0))))
[2019-05-08 16:04:59,600] {logging_mixin.py:95} INFO - [2019-05-08 16:04:59,600] {tfrecordio.py:54} WARNING - Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.
[2019-05-08 16:05:01,985] {logging_mixin.py:95} INFO - [2019-05-08 16:05:01,984] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Create/Read_185)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/0))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/0)
[2019-05-08 16:05:02,002] {logging_mixin.py:95} INFO - [2019-05-08 16:05:02,001] {fn_api_runner.py:427} INFO - Running (((((((((((((((((FlattenAnalysisDatasets/Read)+((ref_AppliedPTransform_AnalyzeDataset/ApplySavedModel[0]/BatchInputs/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_17)+(ref_AppliedPTransform_AnalyzeDataset/ApplySavedModel[0]/ApplySavedModel_18)))+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score/mean_and_var]_19)+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/KeyWithVoid_22)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score_1/mean_and_var]_46))+(((ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score_2/mean_and_var]_73)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/KeyWithVoid_76))+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write))))+((((ref_AppliedPTransform_AnalyzeDataset/TensorSource[compute_and_apply_vocabulary/vocabulary]_100)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/FlattenStringsAndMaybeWeightsLabels_102))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CountPerString:PairWithVoid_104))+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Precombine)+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Write))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[compute_and_apply_vocabulary_1/vocabulary]_158))+(((ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize/quantiles]_216)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/KeyWithVoid_219))+((AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_1/quantiles]_248))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_2/quantiles]_280))+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_3/quantiles]_312)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/KeyWithVoid_315)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine))))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/KeyWithVoid_251)+((AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write))))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/KeyWithVoid_49))+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write)))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/KeyWithVoid_283))+((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write)))+((((ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/FlattenStringsAndMaybeWeightsLabels_160)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CountPerString:PairWithVoid_162))+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Precombine))+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Write)))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write)
[2019-05-08 16:05:02,526] {logging_mixin.py:95} INFO - [2019-05-08 16:05:02,526] {tf_logging.py:115} INFO - Saver not created because there are no variables in the graph to restore
[2019-05-08 16:05:03,837] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,837] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Read)+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Merge)+((((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/FilterProblematicStrings_170))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Precombine))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Group/Write)))
[2019-05-08 16:05:03,855] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,855] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Group/Read)+((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Merge)+(((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/ExtractOutputs)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/SwapStringsAndCounts_179)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_TopPerBundle)_183)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/1))))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/1)))
[2019-05-08 16:05:03,874] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,874] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Read)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Write)
[2019-05-08 16:05:03,886] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,886] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_MergeTopPerBundle)_191)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/FlattenList_192)+(ref_PCollection_PCollection_119/Write)))
[2019-05-08 16:05:03,904] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,904] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/Prepare/Read_195)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/OrderElements_196))+(((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/Map(<lambda at iobase.py:984>)_203)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/WindowInto(WindowIntoFn)_204))+(AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Write))
[2019-05-08 16:05:03,936] {logging_mixin.py:95} INFO - [2019-05-08 16:05:03,936] {fn_api_runner.py:427} INFO - Running (((AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/UnKey_323)+(ref_PCollection_PCollection_201/Write))
[2019-05-08 16:05:04,034] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,034] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/DoOnce/Read_325)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/InjectDefault_326)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/KeyWithVoid_329)+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine))))+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write)
[2019-05-08 16:05:04,113] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,113] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge))+((AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/UnKey_337)+(ref_PCollection_PCollection_209/Write)))
[2019-05-08 16:05:04,262] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,262] {fn_api_runner.py:427} INFO - Running ((((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/DoOnce/Read_339)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/InjectDefault_340))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_342))+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_3/quantiles/Placeholder]_343)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/2)))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/2)
[2019-05-08 16:05:04,288] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,287] {fn_api_runner.py:427} INFO - Running (((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge))+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/UnKey_30)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_33)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine)))))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write)
[2019-05-08 16:05:04,309] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,309] {fn_api_runner.py:427} INFO - Running ((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/UnKey_41))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_43)+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score/mean_and_var/Placeholder_1]_45)+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/4)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/4))))+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score/mean_and_var/Placeholder]_44)+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/3)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/3))))
[2019-05-08 16:05:04,339] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,339] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Merge))+(((AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/UnKey_259))+(ref_PCollection_PCollection_161/Write))
[2019-05-08 16:05:04,443] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,442] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/DoOnce/Read_261)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/InjectDefault_262))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/KeyWithVoid_265)+(AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))
[2019-05-08 16:05:04,511] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,511] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge)+(((AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/UnKey_273))+(ref_PCollection_PCollection_169/Write)))
[2019-05-08 16:05:04,626] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,626] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Merge))+(((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/UnKey_291))+(ref_PCollection_PCollection_181/Write))
[2019-05-08 16:05:04,723] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,723] {fn_api_runner.py:427} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/DoOnce/Read_201)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/InitializeWrite_202))+(ref_PCollection_PCollection_122/Write))+(ref_PCollection_PCollection_123/Write)
[2019-05-08 16:05:04,741] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,741] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/WriteBundles_209))+(ref_PCollection_PCollection_129/Write)
[2019-05-08 16:05:04,757] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,757] {fn_api_runner.py:427} INFO - Running ((ref_PCollection_PCollection_122/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/PreFinalize_210))+(ref_PCollection_PCollection_130/Write)
[2019-05-08 16:05:04,775] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,775] {fn_api_runner.py:427} INFO - Running ((ref_PCollection_PCollection_122/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/FinalizeWrite_211))+(ref_PCollection_PCollection_131/Write)
[2019-05-08 16:05:04,788] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,788] {filebasedsink.py:290} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2019-05-08 16:05:04,917] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,917] {filebasedsink.py:327} INFO - Renamed 1 shards in 0.13 seconds.
[2019-05-08 16:05:04,924] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,924] {fn_api_runner.py:427} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/CreatePath/Read_213)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WaitForVocabularyFile_214)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[compute_and_apply_vocabulary_1/vocabulary/Placeholder]_215)))+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/10))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/10)
[2019-05-08 16:05:04,948] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,948] {fn_api_runner.py:427} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/DoOnce/Read_143)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/InitializeWrite_144))+(ref_PCollection_PCollection_86/Write))+(ref_PCollection_PCollection_87/Write)
[2019-05-08 16:05:04,966] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,966] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Read)+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Merge)+((((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/FilterProblematicStrings_112))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Precombine))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Group/Write)))
[2019-05-08 16:05:04,988] {logging_mixin.py:95} INFO - [2019-05-08 16:05:04,988] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Group/Read)+((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Merge)+(((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/ExtractOutputs)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/SwapStringsAndCounts_121)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_TopPerBundle)_125)))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/0))))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/0)
[2019-05-08 16:05:05,011] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,010] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Create/Read_127)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/1))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/1)
[2019-05-08 16:05:05,025] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,025] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Read)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Write)
[2019-05-08 16:05:05,043] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,043] {fn_api_runner.py:427} INFO - Running (((AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_MergeTopPerBundle)_133))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/FlattenList_134))+(ref_PCollection_PCollection_83/Write)
[2019-05-08 16:05:05,222] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,222] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/Prepare/Read_137)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/OrderElements_138))+(((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/Map(<lambda at iobase.py:984>)_145)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/WindowInto(WindowIntoFn)_146))+(AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Write))
[2019-05-08 16:05:05,249] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,249] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/WriteBundles_151)+(ref_PCollection_PCollection_93/Write))
[2019-05-08 16:05:05,267] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,267] {fn_api_runner.py:427} INFO - Running ((ref_PCollection_PCollection_86/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/PreFinalize_152))+(ref_PCollection_PCollection_94/Write)
[2019-05-08 16:05:05,284] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,284] {fn_api_runner.py:427} INFO - Running ((ref_PCollection_PCollection_86/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/FinalizeWrite_153))+(ref_PCollection_PCollection_95/Write)
[2019-05-08 16:05:05,296] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,296] {filebasedsink.py:290} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2019-05-08 16:05:05,423] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,423] {filebasedsink.py:327} INFO - Renamed 1 shards in 0.13 seconds.
[2019-05-08 16:05:05,432] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,432] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/CreatePath/Read_155)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WaitForVocabularyFile_156)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[compute_and_apply_vocabulary/vocabulary/Placeholder]_157)))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/9)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/9))
[2019-05-08 16:05:05,453] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,453] {fn_api_runner.py:427} INFO - Running (((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/UnKey_57)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_60)+((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write))))
[2019-05-08 16:05:05,475] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,475] {fn_api_runner.py:427} INFO - Running (((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/UnKey_68)+((((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_70)+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_1/mean_and_var/Placeholder_1]_72)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/6)))+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_1/mean_and_var/Placeholder]_71))+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/5))))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/6))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/5)
[2019-05-08 16:05:05,499] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,499] {fn_api_runner.py:427} INFO - Running ((((AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/UnKey_227))+(ref_PCollection_PCollection_141/Write)
[2019-05-08 16:05:05,601] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,600] {fn_api_runner.py:427} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/DoOnce/Read_229)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/InjectDefault_230))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/KeyWithVoid_233))+((AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))
[2019-05-08 16:05:05,682] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,682] {fn_api_runner.py:427} INFO - Running ((((AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/UnKey_241))+(ref_PCollection_PCollection_149/Write)
[2019-05-08 16:05:05,829] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,828] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/DoOnce/Read_243)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/InjectDefault_244)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_246)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize/quantiles/Placeholder]_247))))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/11)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/11))
[2019-05-08 16:05:05,856] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,856] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/UnKey_84)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_87)+((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write))))
[2019-05-08 16:05:05,880] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,880] {fn_api_runner.py:427} INFO - Running (((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/UnKey_95)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_97)))+(((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_2/mean_and_var/Placeholder]_98)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/7))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/7)))+(((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_2/mean_and_var/Placeholder_1]_99)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/8))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/8))
[2019-05-08 16:05:05,909] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,909] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/DoOnce/Read_275)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/InjectDefault_276)+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_278)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_1/quantiles/Placeholder]_279))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/0)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/0))))
[2019-05-08 16:05:05,934] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,933] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/DoOnce/Read_293)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/InjectDefault_294))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/KeyWithVoid_297)+(AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))
[2019-05-08 16:05:05,996] {logging_mixin.py:95} INFO - [2019-05-08 16:05:05,996] {fn_api_runner.py:427} INFO - Running ((AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge))+(((AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/UnKey_305))+(ref_PCollection_PCollection_189/Write))
[2019-05-08 16:05:06,101] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,101] {fn_api_runner.py:427} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/DoOnce/Read_307)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/InjectDefault_308))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_310))+(((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_2/quantiles/Placeholder]_311)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/1))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/1))
[2019-05-08 16:05:06,122] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,122] {fn_api_runner.py:427} INFO - Running (AnalyzeDataset/CreateSavedModel/Flatten/Read)+(ref_PCollection_PCollection_216/Write)
[2019-05-08 16:05:06,135] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,135] {fn_api_runner.py:427} INFO - Running ((((((((ref_AppliedPTransform_AnalyzeDataset/CreateSavedModel/CreateSavedModel/Read_346)+(ref_AppliedPTransform_AnalyzeDataset/CreateSavedModel/BindTensors_348))+(ref_AppliedPTransform_AnalyzeDataset/ComputeDeferredMetadata_349))+(ref_AppliedPTransform_AnalyzeDataset/MakeCheapBarrier_350))+(ref_AppliedPTransform_WriteTransformFn/WriteTransformFn_361))+(ref_PCollection_PCollection_217/Write))+(ref_PCollection_PCollection_225/Write))+((ref_AppliedPTransform_WriteTransformFn/WriteMetadata/WriteMetadata_360)+(ref_PCollection_PCollection_224/Write)))+(ref_PCollection_PCollection_219/Write)
[2019-05-08 16:05:06,257] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,257] {tf_logging.py:115} INFO - Saver not created because there are no variables in the graph to restore
[2019-05-08 16:05:06,280] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,280] {tf_logging.py:115} INFO - Assets added to graph.
[2019-05-08 16:05:06,282] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,282] {tf_logging.py:115} INFO - Assets written to: /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path/tftransform_tmp/1646734ffc3e483fab6739b18bc88d7d/assets
[2019-05-08 16:05:06,324] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,324] {tf_logging.py:115} INFO - SavedModel written to: /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path/tftransform_tmp/1646734ffc3e483fab6739b18bc88d7d/saved_model.pb
[2019-05-08 16:05:06,429] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,429] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_3:0\022/vocab_compute_and_apply_vocabulary_1_vocabulary"
[2019-05-08 16:05:06,429] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,429] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_4:0\022-vocab_compute_and_apply_vocabulary_vocabulary"
[2019-05-08 16:05:06,430] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,430] {tf_logging.py:115} INFO - Saver not created because there are no variables in the graph to restore
[2019-05-08 16:05:06,493] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,492] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/PrepareToClearSharedKeepAlives/Read_352)+(ref_AppliedPTransform_AnalyzeDataset/WaitAndClearSharedKeepAlives_353)
[2019-05-08 16:05:06,509] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,509] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/DoOnce/Read_423)+((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/InitializeWrite_424)+(ref_PCollection_PCollection_263/Write)))+(ref_PCollection_PCollection_262/Write)
[2019-05-08 16:05:06,526] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,526] {fn_api_runner.py:427} INFO - Running ((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/DoOnce/Read_405)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/InitializeWrite_406)+(ref_PCollection_PCollection_251/Write)))+(ref_PCollection_PCollection_250/Write)
[2019-05-08 16:05:06,544] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,544] {fn_api_runner.py:427} INFO - Running (((((((ref_AppliedPTransform_ReadTransformDataset[0]/Read/Read_365)+(ref_AppliedPTransform_ReadTransformDataset[0]/AddKey_366))+((ref_AppliedPTransform_ReadTransformDataset[0]/ParseExamples_367)+(ref_AppliedPTransform_DecodeTransformDataset[0]/ApplyDecodeFn_369)))+(ref_AppliedPTransform_TransformDataset[0]/Batch/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_373))+((((ref_AppliedPTransform_TransformDataset[0]/Transform_374)+(ref_AppliedPTransform_TransformDataset[0]/ConvertAndUnbatch_375))+((ref_AppliedPTransform_TransformDataset[0]/MakeCheapBarrier_376)+(ref_PCollection_PCollection_234/Write)))+((ref_AppliedPTransform_EncodeTransformedDataset[0]_380)+((ref_AppliedPTransform_Materialize[0]/DropNoneKeys_400)+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/WriteBundles_407)))))+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/Pair_408))+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/WindowInto(WindowIntoFn)_409))+(Materialize[0]/Write/Write/WriteImpl/GroupByKey/Write)
[2019-05-08 16:05:06,684] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,684] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_3:0\022/vocab_compute_and_apply_vocabulary_1_vocabulary"
[2019-05-08 16:05:06,684] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,684] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_4:0\022-vocab_compute_and_apply_vocabulary_vocabulary"
[2019-05-08 16:05:06,685] {logging_mixin.py:95} INFO - [2019-05-08 16:05:06,685] {tf_logging.py:115} INFO - Saver not created because there are no variables in the graph to restore
[2019-05-08 16:05:11,623] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,622] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_TransformDataset[0]/PrepareToClearSharedKeepAlives/Read_378)+(ref_AppliedPTransform_TransformDataset[0]/WaitAndClearSharedKeepAlives_379)
[2019-05-08 16:05:11,645] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,645] {fn_api_runner.py:427} INFO - Running (Materialize[0]/Write/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/Extract_414)+(ref_PCollection_PCollection_258/Write))
[2019-05-08 16:05:11,663] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,663] {fn_api_runner.py:427} INFO - Running (ref_PCollection_PCollection_250/Read)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/PreFinalize_415)+(ref_PCollection_PCollection_259/Write))
[2019-05-08 16:05:11,685] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,685] {fn_api_runner.py:427} INFO - Running (ref_PCollection_PCollection_250/Read)+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/FinalizeWrite_416)
[2019-05-08 16:05:11,702] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,702] {filebasedsink.py:290} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2019-05-08 16:05:11,821] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,821] {filebasedsink.py:327} INFO - Renamed 1 shards in 0.12 seconds.
[2019-05-08 16:05:11,889] {logging_mixin.py:95} INFO - [2019-05-08 16:05:11,888] {fn_api_runner.py:427} INFO - Running ((((((ref_AppliedPTransform_ReadTransformDataset[1]/Read/Read_383)+(ref_AppliedPTransform_ReadTransformDataset[1]/AddKey_384))+(ref_AppliedPTransform_ReadTransformDataset[1]/ParseExamples_385))+((ref_AppliedPTransform_DecodeTransformDataset[1]/ApplyDecodeFn_387)+((ref_AppliedPTransform_TransformDataset[1]/Batch/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_391)+((ref_AppliedPTransform_TransformDataset[1]/Transform_392)+(ref_AppliedPTransform_TransformDataset[1]/ConvertAndUnbatch_393)))))+((ref_AppliedPTransform_TransformDataset[1]/MakeCheapBarrier_394)+(ref_PCollection_PCollection_245/Write)))+(ref_AppliedPTransform_EncodeTransformedDataset[1]_398))+((ref_AppliedPTransform_Materialize[1]/DropNoneKeys_418)+((((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/WriteBundles_425)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/Pair_426))+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/WindowInto(WindowIntoFn)_427))+(Materialize[1]/Write/Write/WriteImpl/GroupByKey/Write)))
[2019-05-08 16:05:12,043] {logging_mixin.py:95} INFO - [2019-05-08 16:05:12,042] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_3:0\022/vocab_compute_and_apply_vocabulary_1_vocabulary"
[2019-05-08 16:05:12,043] {logging_mixin.py:95} INFO - [2019-05-08 16:05:12,043] {tf_logging.py:125} WARNING - Expected binary or unicode string, got type_url: "type.googleapis.com/tensorflow.AssetFileDef"
value: "\n\013\n\tConst_4:0\022-vocab_compute_and_apply_vocabulary_vocabulary"
[2019-05-08 16:05:12,044] {logging_mixin.py:95} INFO - [2019-05-08 16:05:12,044] {tf_logging.py:115} INFO - Saver not created because there are no variables in the graph to restore
[2019-05-08 16:05:15,145] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,145] {fn_api_runner.py:427} INFO - Running ((Materialize[1]/Write/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/Extract_432))+(ref_PCollection_PCollection_270/Write)
[2019-05-08 16:05:15,162] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,162] {fn_api_runner.py:427} INFO - Running (ref_PCollection_PCollection_262/Read)+((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/PreFinalize_433)+(ref_PCollection_PCollection_271/Write))
[2019-05-08 16:05:15,180] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,179] {fn_api_runner.py:427} INFO - Running (ref_PCollection_PCollection_262/Read)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/FinalizeWrite_434)
[2019-05-08 16:05:15,193] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,193] {filebasedsink.py:290} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1
[2019-05-08 16:05:15,315] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,315] {filebasedsink.py:327} INFO - Renamed 1 shards in 0.12 seconds.
[2019-05-08 16:05:15,346] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,346] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_TransformDataset[1]/PrepareToClearSharedKeepAlives/Read_396)+(ref_AppliedPTransform_TransformDataset[1]/WaitAndClearSharedKeepAlives_397)
[2019-05-08 16:05:15,361] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,361] {fn_api_runner.py:427} INFO - Running (ref_AppliedPTransform_WriteMetadata/Create/Read_356)+(ref_AppliedPTransform_WriteMetadata/WriteMetadata_357)
[2019-05-08 16:05:15,375] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,375] {fn_api_runner.py:427} INFO - Running (ref_PCollection_PCollection_225/Read)+(ref_AppliedPTransform_WriteTransformFn/WaitOnWriteMetadataDone_362)
[2019-05-08 16:05:15,398] {logging_mixin.py:95} INFO - [2019-05-08 16:05:15,398] {tf_logging.py:115} INFO - Cleaning up temp path /Users/benjamin.wang/devel/github/tutorial_tfx/tfx_outputs/pipelines/chicago_taxi_simple/Transform/transform_output/4/.temp_path on executor success
[2019-05-08 16:05:15,405] {python_operator.py:113} INFO - Done. Returned value was: None
[2019-05-08 16:05:19,601] {logging_mixin.py:95} INFO - [2019-05-08 16:05:19,600] {jobs.py:2562} INFO - Task exited with return code 0
